{"searchDocs":[{"title":"üìò Concepts","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/agent-tools/concepts","content":"","keywords":"","version":"Next"},{"title":"Tool calling‚Äã","type":1,"pageTitle":"üìò Concepts","url":"/mdb-aws-agents-lab/docs/agent-tools/concepts#tool-calling","content":" Tool calling, interchangeably called function calling allows an LLM to use external tools such as APIs, databases, specialized machine learning models etc.  In AI agents, an LLM can have access to multiple tools. Given a user query, the LLM decides which tool to invoke and the arguments for the tool call. These arguments are used to execute the tool call and the output is returned back to the LLM to inform its next steps.  The easiest way to define tools in LangChain is using the @tool decorator. The decorator makes tools out of functions by using the function name as the tool name by default, and the function's docstring as the tool's description. The tool call inturn consists of a tool name, arguments, and an optional identifier.  An example of a tool in LangChain is as follows:  @tool(&quot;search-tool&quot;, return_direct=True) def search(query: str) -&gt; str: &quot;&quot;&quot;Look up things online.&quot;&quot;&quot; return &quot;MongoDB&quot;   An example of a tool call is as follows:  { &quot;name&quot;: &quot;search-tool&quot;, &quot;args&quot;: { &quot;query&quot;: &quot;What is MongoDB?&quot; }, &quot;id&quot;: &quot;call_H5TttXb423JfoulF1qVfPN3m&quot; }  ","version":"Next","tagName":"h2"},{"title":"üëê Add memory to the agent","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/adding-memory/adding-memory","content":"üëê Add memory to the agent The final step in this lab is to add conversational message history as a form of memory for our agent. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 12: Add memory to the agent section in the notebook to add memory to our MongoDB learning assistant. The answers for code blocks in this section are as follows: CODE_BLOCK_22 Answer config = {&quot;configurable&quot;: {&quot;thread_id&quot;: thread_id}} ","keywords":"","version":"Next"},{"title":"üìò Concepts","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/adding-memory/concepts","content":"","keywords":"","version":"Next"},{"title":"Checkpoints‚Äã","type":1,"pageTitle":"üìò Concepts","url":"/mdb-aws-agents-lab/docs/adding-memory/concepts#checkpoints","content":" Checkpoints in LangGraph are a snapshot of the graph state. This is how AI applications built using LangGraph persist short-term and long-term memory.  ","version":"Next","tagName":"h2"},{"title":"Thread IDs‚Äã","type":1,"pageTitle":"üìò Concepts","url":"/mdb-aws-agents-lab/docs/adding-memory/concepts#thread-ids","content":" Thread IDs are unique IDs assigned to memory checkpoints in LangGraph, allowing it to distinguish between conversation threads, facilitate human-in-the loop workflows and allow users to review and debug graph executions. ","version":"Next","tagName":"h2"},{"title":"üëê Create a vector search index","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/agent-tools/create-vector-search-index","content":"üëê Create a vector search index To retrieve documents using vector search, you must configure a vector search index on the collection you want to perform vector search against. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 4: Create a vector search index section in the notebook to create a vector search index. The answers for code blocks in this section are as follows: CODE_BLOCK_1 Answer mongodb_client[DB_NAME][VS_COLLECTION_NAME] CODE_BLOCK_2 Answer vs_collection.create_search_index(model=model) To verify that the index was created, navigate to Search Indexes for the chunked_articles collection. The index is ready to use once the status changes from PENDING to READY.","keywords":"","version":"Next"},{"title":"üëê Import data","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/agent-tools/import-data","content":"üëê Import data The MongoDB learning assistant has two tools- a vector search tool to retrieve information to answer questions about MongoDB, and another tool to get the content of articles in our Developer Center for summarization. Let's import the data required by these tools into two MongoDB collections. This is as simple as making a GET request to a serverless AWS Lambda function that we have created for you. Run the cells under the Step 3: Import data section in the notebook to import the data required by our agent's tools, into MongoDB collections. To verify that the data has been imported into your MongoDB cluster, navigate to the Overview page in the Atlas UI. In the Clusters section, select the cluster you just created and click Browse collections. Ensure that you see a database called mongodb_agents_lab, and two collections namely chunked_articles and full_articles under it. Note the number and format of documents in both the collections.","keywords":"","version":"Next"},{"title":"üëê Get your connection string","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/agent-tools/get-connection-string","content":"üëê Get your connection string In order to ingest data into your cluster later in the lab, you will need to get the connection string for your cluster. In the Atlas UI, navigate to the Overview page. In the Clusters section, select the cluster you just created and click Connect. A modal will display several ways to connect to your database. Select Drivers. Look for your connection string. It should look something like mongodb+srv://&lt;username&gt;:&lt;password&gt;@&lt;cluster-url&gt;/ Click the copy button next to your connection string to copy it to your clipboard. Paste the connection string somewhere safe. tip Don't forget to replace &lt;password&gt; with the password you set when you created the cluster.","keywords":"","version":"Next"},{"title":"üëê Create agent tools","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/agent-tools/create-agent-tools","content":"üëê Create agent tools The easiest way to define custom tools for agents in LangChain is using the @tool decorator. The decorator makes tools out of functions by using the function name as the tool name by default, and the function's docstring as the tool's description. We want the MongoDB learning assistant to have access to the following tools: get_information_for_question_answering: Uses vector search to retrieve information to answer questions get_article_content_for_summarization: Gets the content of articles for summarization Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 5: Create agent tools section in the notebook to create tools for the agent to use. The answers for code blocks in this section are as follows: CODE_BLOCK_3 Answer embedding_model.encode(text) CODE_BLOCK_4 Answer get_embedding(user_query) CODE_BLOCK_5 Answer [ { &quot;$vectorSearch&quot;: { &quot;index&quot;: VS_INDEX_NAME, &quot;path&quot;: &quot;embedding&quot;, &quot;queryVector&quot;: query_embedding, &quot;numCandidates&quot;: 150, &quot;limit&quot;: 5, } }, { &quot;$project&quot;: { &quot;_id&quot;: 0, &quot;body&quot;: 1, &quot;score&quot;: {&quot;$meta&quot;: &quot;vectorSearchScore&quot;}, } }, ] CODE_BLOCK_6 Answer vs_collection.aggregate(pipeline) CODE_BLOCK_7 Answer mongodb_client[DB_NAME][FULL_COLLECTION_NAME] CODE_BLOCK_8 Answer {&quot;title&quot;: user_query} CODE_BLOCK_9 Answer {&quot;_id&quot;: 0, &quot;body&quot;: 1} CODE_BLOCK_10 Answer full_collection.find_one(query, projection) ","keywords":"","version":"Next"},{"title":"üìò Running code in Jupyter Notebooks","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/agent-tools/jupyter_notebooks","content":"üìò Running code in Jupyter Notebooks Jupyter Notebooks are an interactive Python environment. Cells in a Jupyter notebook are a modular unit of code or text that you can execute and view outputs for. To run a cell, highlight it and click the Run icon in the toolbar at the top. When a cell is running, you will see a * in the square brackets ([ ]) against the cell. When a cell is finished running successfully, you will see a number appear in the [ ] with no error traceback after the cell. If an error occurred while running a cell, you will see an error traceback after the cell. To fix errors, you may need to update previous cells. If you do, re-run all the cells following the one(s) you updated. To interrupt a running cell, click the Stop icon in the toolbar at the top.","keywords":"","version":"Next"},{"title":"üëê Request access to LLMs in Bedrock","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/aws/bedrock","content":"üëê Request access to LLMs in Bedrock In this lab, we will use chat completion LLMs available on Amazon Bedrock. But first, you need to enable the models. Once you have joined the workshop, navigate to the AWS console by clicking Open AWS console in the sidebar under AWS account access. Once logged into the console AWS console, navigate to Amazon Bedrock. In the Bedrock console, scroll down to Bedrock configurations in the sidebar and click Model access Under Base models, click on Available to request against the Claude 3 Sonnet model. In the modal that appears, click Request model access. Scroll to the bottom of the page and click Next. On the following page, click Submit to submit the model access request. It takes a few seconds to provision access. Once access has been granted you should see Access granted against the model name. That's it! You are now ready to use the Claude Sonnet 3 model to build an AI agent.","keywords":"","version":"Next"},{"title":"üìò What are AI agents?","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/ai-agents/what-are-ai-agents","content":"üìò What are AI agents? An AI agent is a system that uses an LLM to reason through a problem, create a plan to solve the problem, and execute the plan with the help of a set of tools. In multi-agent systems, two or more agents collaborate or orchestrate and delegate tasks to solve problems. This way, agentic systems can handle complex, multi-step queries, and also self-revise and refine responses.","keywords":"","version":"Next"},{"title":"üìò When to use AI agents?","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/ai-agents/when-to-use-agents","content":"üìò When to use AI agents? AI agents are best suited for complex, multi-step tasks that require integration of multiple capabilities, such as question-answering, analysis, task execution etc. to arrive at the final answer or outcome. An active area of research is to have AI agents learn from their past interactions to build personalized and adaptive experiences. Here are some examples of tasks/questions that DO NOT require an AI agent: Who was the first president of the United States? The information required to answer this question is very likely present in the parametric knowledge of most LLMs. Hence, this question can be answer using a simple prompt to an LLM. What is the reimbursement policy for meals for my company? The information required to answer this question is most likely not present in the parametric knowledge of available LLMs. However, this question can easily be answered using Retrieval Augmented Generation (RAG) using a knowledge base consisting of your company's data. This still does not require an agent. Here are some use cases for AI agents: How has the trend in the average daily calorie intake among adults changed over the last decade in the United States, and what impact might this have on obesity rates? Additionally, can you provide a graphical representation of the trend in obesity rates over this period? This question involves multiple sub-tasks such as data aggregation, visualization, and reasoning. Hence, this is a good use case for an AI agent. Creating a personalized learning assistant that can adjust its language, examples, and methods based on the student‚Äôs responses. This is an example of a complex task which also involves user personalization. Hence, this is a good fit for an AI agent.","keywords":"","version":"Next"},{"title":"üëê Setup dev environment in Sagemaker Studio","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/aws/sagemaker-studio","content":"üëê Setup dev environment in Sagemaker Studio You will be using a Jupyter Notebook in Sagemaker Studio as the dev environment for the rest of the lab. Start by navigating to Amazon Sagemaker from the AWS Console. In the sidebar, click on Domains under Admin configurations and select the pre-configured domain. Under Domain Details, click on Space management. You should see a pre-configured space appear. Click Launch Studio to launch a Sagemaker Studio environment in this space. In the Sagemaker Studio console, select the Git dropdown from the menu bar at the top and then select Clone Git Repository In the modal that appears, paste the following URL in the Git repository URL box, click the Clone https://... message from the drop-down, and click the Clone button:https://github.com/mongodb-developer/mdb-aws-agents-lab-notebooks.git Once the repo is cloned, you will see the content of the repo in the sidebar. Double-click on the file named notebook_template.ipynb. This is where you will fill in code for the rest of the lab. When prompted to select the notebook environment, proceed wih the defaults by clicking the Select button. That's it! You are ready to start building your AI agent!","keywords":"","version":"Next"},{"title":"üëê Log into your temporary AWS account","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/aws/workshop-studio","content":"üëê Log into your temporary AWS account In this lab, we will use LLMs from Amazon Bedrock and JupyterLab as the dev environment via Sagemaker Studio. To use these AWS services, you will need an AWS account. We have provisioned a temporary account for you via AWS Workshop Studio. Start by navigating to Workshop Studio. Select the Email one-time password (OTP) option. Enter the email address you used to register for the event and click Send passcode. Check your email for the OTP. In the next modela, enter this OTP and click Sign in Once signed in, enter the 12-digit event access code provided by your facilitator and click Next On the next page, check the Terms and Conditions box and click Join event. That's all! You now have a temporary AWS account for the workshop.","keywords":"","version":"Next"},{"title":"üìò Components of AI agents","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/ai-agents/components-of-agents","content":"","keywords":"","version":"Next"},{"title":"Perception‚Äã","type":1,"pageTitle":"üìò Components of AI agents","url":"/mdb-aws-agents-lab/docs/ai-agents/components-of-agents#perception","content":" Perception, in the context of AI agents, is the mechanism by which the agent gathers information about its environment. Text inputs are currently the most common perception mechanism for AI agents, but we are slowly progressing towards audio, visual, multimodal or even physical sensory inputs.  ","version":"Next","tagName":"h2"},{"title":"Planning and reasoning‚Äã","type":1,"pageTitle":"üìò Components of AI agents","url":"/mdb-aws-agents-lab/docs/ai-agents/components-of-agents#planning-and-reasoning","content":" AI agents use user prompts, self-prompting and feedback loops to break down complex tasks, reason through their execution plan and refine it as needed.  Some common design patterns for planning and reasoning in AI agents are as follows:  ","version":"Next","tagName":"h2"},{"title":"Chain of Thought (Cot) Prompting‚Äã","type":1,"pageTitle":"üìò Components of AI agents","url":"/mdb-aws-agents-lab/docs/ai-agents/components-of-agents#chain-of-thought-cot-prompting","content":" In this approach, the LLM is prompted to generate a step-by-step explanation or reasoning process for a given task or problem.  Here is an example of a zero-shot CoT prompt:  Given a question, write out in a step-by-step manner your reasoning for how you will solve the problem to be sure that your conclusion is correct. Avoid simply stating the correct answer at the outset.  ","version":"Next","tagName":"h3"},{"title":"ReAct (Reason + Act)‚Äã","type":1,"pageTitle":"üìò Components of AI agents","url":"/mdb-aws-agents-lab/docs/ai-agents/components-of-agents#react-reason--act","content":" In this approach, the LLM is prompted to generate reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans, while actions allow it to interface with external sources or tools, to gather additional information.  Here is an example of a ReAct prompt:  Answer the following questions as best you can. You have access to the following tools:{tools} ## Use the following format: Question: the input question you must answer Thought: you should always think about what to do Action: the action to take, should be one of [{tool_names}] Action Input: the input to the action Observation: the result of the action ... (this Thought/Action/Action Input/Observation can repeat N times) Thought: I now know the final answer Final Answer: the final answer to the original input question   ","version":"Next","tagName":"h3"},{"title":"Reflection‚Äã","type":1,"pageTitle":"üìò Components of AI agents","url":"/mdb-aws-agents-lab/docs/ai-agents/components-of-agents#reflection","content":" Reflection involves prompting an LLM to reflect on and critique past actions, sometimes incorporating additional external information such as tool observations. The generation-reflection loop is run several times before returning the final response to the user. Reflection trades a bit of extra compute for a shot at better output quality.  ","version":"Next","tagName":"h3"},{"title":"Tools‚Äã","type":1,"pageTitle":"üìò Components of AI agents","url":"/mdb-aws-agents-lab/docs/ai-agents/components-of-agents#tools","content":" Tools are interfaces for AI agents to interact with the external world in order to achieve their objectives. These can be APIs, vector databases, or even specialized machine learning models.  ","version":"Next","tagName":"h2"},{"title":"Memory‚Äã","type":1,"pageTitle":"üìò Components of AI agents","url":"/mdb-aws-agents-lab/docs/ai-agents/components-of-agents#memory","content":" The memory component allows AI agents to store and recall past conversations, enabling them to learn from these interactions.  There are two main types of memory for AI agents:  Short-term memory: Stores and retrieves information from a specific conversation. Long-term memory: Stores, retrieves and updates information based on multiple conversations had over a period of time. ","version":"Next","tagName":"h2"},{"title":"üìò Concepts","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/create-agent/concepts","content":"","keywords":"","version":"Next"},{"title":"Graph State‚Äã","type":1,"pageTitle":"üìò Concepts","url":"/mdb-aws-agents-lab/docs/create-agent/concepts#graph-state","content":" Each graph in has a state which is a shared data structure that all the nodes can access and make updates to. You can define custom attributes within the state depending on what parameters you want to track across the nodes of the graph.  ","version":"Next","tagName":"h2"},{"title":"Nodes‚Äã","type":1,"pageTitle":"üìò Concepts","url":"/mdb-aws-agents-lab/docs/create-agent/concepts#nodes","content":" Nodes in LangGraph are Python functions that encode the logic of your agents. They receive the current state of the graph as input, perform some computation and return an updated state.  ","version":"Next","tagName":"h2"},{"title":"Edges‚Äã","type":1,"pageTitle":"üìò Concepts","url":"/mdb-aws-agents-lab/docs/create-agent/concepts#edges","content":" Edges in LangGraph are Python functions that determine which graph node to execute next based on the current state of the graph. Edges can be conditional or fixed. ","version":"Next","tagName":"h2"},{"title":"üëê Define graph nodes","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/create-agent/define-graph-nodes","content":"üëê Define graph nodes Let's define the nodes of our graph. Our agent will have two nodes- an agent node and a tool node. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 8: Define graph nodes section in the notebook to define the nodes of the graph. The answers for code blocks in this section are as follows: CODE_BLOCK_14 Answer state[&quot;messages&quot;] CODE_BLOCK_15 Answer llm_with_tools.invoke(messages) CODE_BLOCK_16 Answer tool.invoke(tool_call[&quot;args&quot;]) ","keywords":"","version":"Next"},{"title":"üëê Define graph state","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/create-agent/define-graph-state","content":"üëê Define graph state Let's start by defining the state of our agent's graph. Run the cells under the Step 6: Define graph state section in the notebook to define the state of the graph for our MongoDB learning assistant.","keywords":"","version":"Next"},{"title":"üëê Instantiate the LLM","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/create-agent/instantiate-llm","content":"üëê Instantiate the LLM Now let's instantiate the LLM that will serve as the &quot;brain&quot; of our agent, and give it access to the tools we defined previously. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 7: Instantiate the LLM section in the notebook to initialize the LLM for our agent and give it access to tools. The answers for code blocks in this section are as follows: CODE_BLOCK_11 Answer ChatBedrock( model_id=&quot;anthropic.claude-3-sonnet-20240229-v1:0&quot;, model_kwargs=dict(temperature=0) ) CODE_BLOCK_12 Answer llm.bind_tools(tools) CODE_BLOCK_13 Answer prompt | bind_tools ","keywords":"","version":"Next"},{"title":"üëê Build and execute the graph","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/create-agent/build-and-execute-graph","content":"üëê Build and execute the graph Now that we have defined the nodes and edges of the graph, let's put the graph together and execute it to ensure that our agent is working as expected. Fill in any &lt;CODE_BLOCK_N&gt; placeholders and run the cells under the Step 10: Build the graph and Step 11: Execute the graph sections in the notebook to build and execute the graph. The answers for code blocks in this section are as follows: CODE_BLOCK_17 Answer graph.add_node(&quot;agent&quot;, agent) CODE_BLOCK_18 Answer graph.add_node(&quot;tools&quot;, tool_node) CODE_BLOCK_19 Answer graph.add_edge(START, &quot;agent&quot;) CODE_BLOCK_20 Answer graph.add_edge(&quot;tools&quot;, &quot;agent&quot;) CODE_BLOCK_21 Answer graph.add_conditional_edges( &quot;agent&quot;, route_tools, {&quot;tools&quot;: &quot;tools&quot;, END: END}, ) ","keywords":"","version":"Next"},{"title":"üëê Define conditional edges","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/create-agent/define-conditional-edges","content":"üëê Define conditional edges Edges in a LangGraph graph can be fixed or conditional. For conditional edges, we need a routing function to conditionally route the workflow to different nodes. Run the cells under the Step 9: Define conditional edges section in the notebook to define the routing function for the one conditional edge in our graph.","keywords":"","version":"Next"},{"title":"Introduction","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/intro","content":"Introduction Lab goals\tLearn the basics of building AI agentsWhat you'll learn\tWhat are AI agents When to use AI agents? Components of an AI agent Agent Architectures Building an AI agent Adding memory to agents Time to complete\t90 mins note For this lab, you will need: Basic to intermediate knowledge of PythonA laptop with the latest version of Python installed In the navigation bar and in some pages, you will notice some icons. Here is their meaning: Icon\tMeaning\tDescriptionüìò\tLecture material\tIf you are following along in an instructor-led session, they probably have covered this already. üëê\tHands-on content\tGet ready to do some hands-on work. You should follow these steps. üìö\tDocumentation\tReference documentation for hands-on portions of the lab. ü¶π\tAdvanced content\tThis content isn't covered during the lab, but if you're interested in learning more, you can check it out.","keywords":"","version":"Next"},{"title":"üëê Create your account","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/mongodb-atlas/create-account","content":"","keywords":"","version":"Next"},{"title":"üéØ Summary","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/summary","content":"üéØ Summary Congratulations! Following this lab, you have successfully: learned what are AI agentslearned when to use AI agentslearned about different agent architecturesbuilt an AI agent with memory Here are some resources that you might find helpful: MongoDB Developer CenterGenAI Code Examples RepositoryGenAI Community Forums","keywords":"","version":"Next"},{"title":"Sign up for MongoDB Atlas‚Äã","type":1,"pageTitle":"üëê Create your account","url":"/mdb-aws-agents-lab/docs/mongodb-atlas/create-account#sign-up-for-mongodb-atlas","content":" Start by going to the MongoDB website and creating your account.  tip Creating a MongoDB Atlas account is free and does not require a credit card.  You will be greeted by a form similar to the one below.    info If you are doing this lab at an event, you should use the same email address you used to register for the event.  Complete the form and click the Create Your Atlas Account button.  ","version":"Next","tagName":"h2"},{"title":"Verify your email address‚Äã","type":1,"pageTitle":"üëê Create your account","url":"/mdb-aws-agents-lab/docs/mongodb-atlas/create-account#verify-your-email-address","content":" You will receive an email from MongoDB asking you to verify your email address. Click the link in the email to verify your email address.    caution If you haven't received the email within two minutes, check your spam folder.  ","version":"Next","tagName":"h2"},{"title":"Finish the onboarding‚Äã","type":1,"pageTitle":"üëê Create your account","url":"/mdb-aws-agents-lab/docs/mongodb-atlas/create-account#finish-the-onboarding","content":" You will be redirected to the MongoDB Atlas onboarding wizard. Fill in the form and click Finish to continue. ","version":"Next","tagName":"h2"},{"title":"üëê Deploy a database cluster","type":0,"sectionRef":"#","url":"/mdb-aws-agents-lab/docs/mongodb-atlas/create-cluster","content":"","keywords":"","version":"Next"},{"title":"Security quickstart‚Äã","type":1,"pageTitle":"üëê Deploy a database cluster","url":"/mdb-aws-agents-lab/docs/mongodb-atlas/create-cluster#security-quickstart","content":" By default, your MongoDB Atlas deployment is completely locked-down. You need to configure the network settings and create a user to access your database.  While your deployment is being provisioned, you will see the security quickstart dialog.  ","version":"Next","tagName":"h2"},{"title":"Network access‚Äã","type":1,"pageTitle":"üëê Deploy a database cluster","url":"/mdb-aws-agents-lab/docs/mongodb-atlas/create-cluster#network-access","content":" First, you should Allow Access from Anywhere. You will see a field pre-populated with the IP address 0.0.0.0/0. This means that you can connect to your database from any IP address including the virtual environment you will use for this lab. Click Add IP Address to add this IP address to the network allowlist.  caution It is dangerous to expose your database to the entire world. Never do this is a real production environment.  ","version":"Next","tagName":"h3"},{"title":"Database user‚Äã","type":1,"pageTitle":"üëê Deploy a database cluster","url":"/mdb-aws-agents-lab/docs/mongodb-atlas/create-cluster#database-user","content":" Next, you need to create a database user. Pick any username and password you want. This will be used when you want to connect to your database. Click Create Database User to create the user.  Atlas might create the user automatically for you if you have just created your account. In this case, the username and password will match your Atlas account credentials.  tip Make sure to remember your username and password. You will need them later. For the sake of this workshop, it might be preferable to use a simple password that you'll remember over a more secure one.  ","version":"Next","tagName":"h3"},{"title":"Manual network access configuration‚Äã","type":1,"pageTitle":"üëê Deploy a database cluster","url":"/mdb-aws-agents-lab/docs/mongodb-atlas/create-cluster#manual-network-access-configuration","content":" If you don't see a button to Allow Access from Anywhere, you should close the dialog and go to the Network Access tab under the Security section in the left sidebar. Click on the Add IP Address button, add the IP address 0.0.0.0/0 and click Confirm.  ","version":"Next","tagName":"h2"},{"title":"That's all!‚Äã","type":1,"pageTitle":"üëê Deploy a database cluster","url":"/mdb-aws-agents-lab/docs/mongodb-atlas/create-cluster#thats-all","content":" That's all! You have a new database cluster. If everything goes well, you should see your newly created cluster on the Database tab under the Deployment section.   ","version":"Next","tagName":"h2"}],"options":{"id":"default"}}